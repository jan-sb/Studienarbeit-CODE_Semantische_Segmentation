{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jan/anaconda3/envs/studi/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2025-03-04 13:59:03.249466: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-04 13:59:03.800790: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from Helper.ml_models import * \n",
    "import ray.cloudpickle as pickle\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping von Mapillary Vistas IDs auf Cityscapes IDs (detaillierter)\n",
    "mapillary_to_cityscapes = {\n",
    "    # Road-related Klassen\n",
    "    21: 0,   # Road -> Road\n",
    "    16: 0,   # Driveway -> Road\n",
    "    17: 0,   # Parking -> Road\n",
    "    18: 0,   # Parking Aisle -> Road\n",
    "    22: 0,   # Road Shoulder -> Road\n",
    "    23: 0,   # Service Lane -> Road\n",
    "\n",
    "    # Sidewalk\n",
    "    24: 1,   # Sidewalk -> Sidewalk\n",
    "    19: 1,   # Pedestrian Area -> Sidewalk\n",
    "    4: 1,    # Curb -> Sidewalk\n",
    "\n",
    "    # Building-related Klassen\n",
    "    27: 2,   # Building -> Building\n",
    "    28: 2,   # Garage -> Building\n",
    "    29: 2,   # Tunnel -> Building\n",
    "    26: 2,   # Bridge -> Building\n",
    "\n",
    "    # Wall\n",
    "    12: 3,   # Wall -> Wall\n",
    "\n",
    "    # Fence-related Klassen\n",
    "    5: 4,    # Fence -> Fence\n",
    "    6: 4,    # Guard Rail -> Fence\n",
    "    7: 4,    # Barrier -> Fence\n",
    "    2: 4,    # Ambiguous Barrier -> Fence\n",
    "    3: 4,    # Concrete Block -> Fence\n",
    "    8: 4,    # Road Median -> Fence\n",
    "    9: 4,    # Road Side -> Fence\n",
    "    11: 4,   # Temporary Barrier -> Fence\n",
    "\n",
    "    # Poles\n",
    "    85: 5,   # Pole -> Pole\n",
    "    86: 5,   # Pole Group -> Pole\n",
    "    88: 5,   # Utility Pole -> Pole\n",
    "\n",
    "    # Traffic Lights\n",
    "    90: 6,   # Traffic Light - General -> Traffic Light\n",
    "    91: 6,   # Traffic Light - Pedestrians -> Traffic Light\n",
    "    92: 6,   # Traffic Light - Upright -> Traffic Light\n",
    "    93: 6,   # Traffic Light - Horizontal -> Traffic Light\n",
    "    94: 6,   # Traffic Light - Cyclists -> Traffic Light\n",
    "    95: 6,   # Traffic Light - Other -> Traffic Light\n",
    "\n",
    "    # Traffic Signs\n",
    "    99: 7,   # Traffic Sign (Front) -> Traffic Sign\n",
    "    100: 7,  # Traffic Sign (Front) -> Traffic Sign\n",
    "    103: 7,  # Traffic Sign - Temporary (Front) -> Traffic Sign\n",
    "\n",
    "    # Vegetation\n",
    "    64: 8,   # Vegetation -> Vegetation\n",
    "\n",
    "    # Terrain\n",
    "    63: 9,   # Terrain -> Terrain\n",
    "    59: 9,   # Mountain -> Terrain\n",
    "    60: 9,   # Sand -> Terrain\n",
    "    62: 9,   # Snow -> Terrain\n",
    "\n",
    "    # Sky\n",
    "    61: 10,  # Sky -> Sky\n",
    "\n",
    "    # Person\n",
    "    30: 11,  # Person -> Person\n",
    "    31: 11,  # Person Group -> Person\n",
    "\n",
    "    # Riders (Fahrer)\n",
    "    32: 12,  # Bicyclist -> Rider\n",
    "    33: 12,  # Motorcyclist -> Rider\n",
    "    34: 12,  # Other Rider -> Rider\n",
    "\n",
    "    # Vehicles\n",
    "    108: 13, # Car -> Car\n",
    "    115: 13, # Vehicle Group -> Car\n",
    "\n",
    "    114: 14, # Truck -> Truck\n",
    "    113: 14, # Trailer -> Truck\n",
    "\n",
    "    107: 15, # Bus -> Bus\n",
    "\n",
    "    111: 16, # On Rails -> Train\n",
    "\n",
    "    110: 17, # Motorcycle -> Motorcycle\n",
    "\n",
    "    105: 18, # Bicycle -> Bicycle\n",
    "\n",
    "    # Alles andere als \"Unlabeled\"\n",
    "    123: 19, # Unlabeled -> Unlabeled\n",
    "}\n",
    "\n",
    "# Falls eine Klasse nicht gemappt wurde, soll sie als \"unlabeled\" behandelt werden\n",
    "default_cityscapes_label = 19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def map_model_output_to_cityscapes(output_tensor):\n",
    "    \"\"\"\n",
    "    Konvertiert den Modell-Output (2D-Tensor) mit 124 Klassen in einen Tensor mit 20 Cityscapes-Klassen.\n",
    "    \n",
    "    Der Input ist ein 2D-Tensor (H x W), in dem jeder Pixel die vom Modell vorhergesagte Mapillary Vistas Klasse (0-123) repräsentiert.\n",
    "    Mithilfe des 'mapillary_to_cityscapes'-Mappings wird jeder Pixelwert in die entsprechende Cityscapes Klasse umgewandelt.\n",
    "    Falls ein Pixelwert nicht im Mapping vorhanden ist, wird 'default_cityscapes_label' (19) zugewiesen.\n",
    "    \n",
    "    Args:\n",
    "        output_tensor (torch.Tensor): 2D-Tensor (H x W) mit Mapillary Vistas Label-IDs.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: 2D-Tensor (H x W) mit den gemappten Cityscapes Label-IDs (0-19).\n",
    "    \"\"\"\n",
    "    # Initialisiere den gemappten Tensor mit dem Default-Wert (z.B. Unlabeled: 19)\n",
    "    mapped_tensor = torch.full_like(output_tensor, fill_value=default_cityscapes_label)\n",
    "    \n",
    "    # Iteriere über das Mapping und weise die entsprechenden Cityscapes IDs zu\n",
    "    for mapillary_id, cityscapes_id in mapillary_to_cityscapes.items():\n",
    "        mapped_tensor[output_tensor == mapillary_id] = cityscapes_id\n",
    "        \n",
    "    return mapped_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data leaks found.\n"
     ]
    }
   ],
   "source": [
    "# Cityscapes K-Fold Dataset Initialisierung\n",
    "cityscapes_dataset = K_Fold_Dataset(\n",
    "    image_dir='/home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/CityscapesDaten/images',\n",
    "    annotation_dir='/home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/CityscapesDaten/semantic',\n",
    "    k_fold_csv_dir='/home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/Daten/CityscapesDaten',\n",
    "    leave_out_fold=0\n",
    ")\n",
    "\n",
    "# Datenlecks prüfen\n",
    "cityscapes_dataset.check_for_data_leaks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading MOdel Function\n",
    "def load_checkpointed_model_ray(model_name, checkpoint_path, num_classes=None):\n",
    "    # Hier sicherstellen, dass skip_local_load übergeben wird:\n",
    "    loaded_model = MapillaryTrainedModel(\n",
    "        model_name=model_name,\n",
    "        width=520,\n",
    "        height=520,\n",
    "        weights_name='',\n",
    "        skip_local_load=True  # WICHTIG!\n",
    "    )\n",
    "    with open(checkpoint_path, \"rb\") as fp:\n",
    "        checkpoint_data = pickle.load(fp)\n",
    "    loaded_model.model.load_state_dict(checkpoint_data[\"model_state\"], strict=True)\n",
    "    if \"optimizer_state\" in checkpoint_data:\n",
    "        loaded_model.optimizer.load_state_dict(checkpoint_data[\"optimizer_state\"])\n",
    "    return loaded_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluierung für Modell: fcn_resnet101\n",
      "Using CUDA GPU\n",
      "Model loaded: fcn_resnet101 | Device: cuda \n",
      "Error loading Model with Epoch latest: Error(s) in loading state_dict for FCN:\n",
      "\tsize mismatch for classifier.4.weight: copying a param with shape torch.Size([20, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([124, 512, 1, 1]).\n",
      "\tsize mismatch for classifier.4.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([124]).\n",
      "Skipping local .pth load due to error above.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating fcn_resnet101: 100%|██████████| 695/695 [00:40<00:00, 17.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ergebnisse für fcn_resnet101: mIoU = 0.4804\n",
      "\n",
      "Evaluierung für Modell: deeplabv3_resnet50\n",
      "Using CUDA GPU\n",
      "Model loaded: deeplabv3_resnet50 | Device: cuda \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating deeplabv3_resnet50: 100%|██████████| 695/695 [00:36<00:00, 19.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ergebnisse für deeplabv3_resnet50: mIoU = 0.4747\n",
      "\n",
      "Evaluierung für Modell: fcn_resnet50\n",
      "Using CUDA GPU\n",
      "Model loaded: fcn_resnet50 | Device: cuda \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating fcn_resnet50: 100%|██████████| 695/695 [00:34<00:00, 20.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ergebnisse für fcn_resnet50: mIoU = 0.4728\n",
      "\n",
      "Evaluierung für Modell: deeplabv3_resnet101\n",
      "Using CUDA GPU\n",
      "Model loaded: deeplabv3_resnet101 | Device: cuda \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating deeplabv3_resnet101: 100%|██████████| 695/695 [00:42<00:00, 16.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ergebnisse für deeplabv3_resnet101: mIoU = 0.4726\n",
      "\n",
      "Evaluationsergebnisse wurden gespeichert in: /home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/FINAL_DATEN/evaluation_results_mapillary_on_cityscapes.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Lade die best_checkpoints-Datei\n",
    "best_checkpoints_path = \"/home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/FINAL_DATEN/best_checkpoints_Mapillary.json\"\n",
    "with open(best_checkpoints_path, \"r\") as f:\n",
    "    best_checkpoints = json.load(f)\n",
    "\n",
    "# Erstelle einen DataLoader für das Testset des Cityscapes-Datensatzes\n",
    "test_loader = DataLoader(cityscapes_dataset.test_dataset, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "evaluation_results = {}\n",
    "\n",
    "for model_name, checkpoint_path in best_checkpoints.items():\n",
    "    print(f\"\\nEvaluierung für Modell: {model_name}\")\n",
    "    if not checkpoint_path or not os.path.isfile(checkpoint_path):\n",
    "        print(f\"[WARNING] Checkpoint für {model_name} ungültig oder nicht gefunden. Überspringe dieses Modell.\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Lade das Modell (auf Mapillary trainiert) aus dem Checkpoint\n",
    "        model_loaded = load_checkpointed_model_ray(model_name, checkpoint_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Fehler beim Laden von {model_name}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    model_loaded.model.to(device)\n",
    "    model_loaded.model.eval()\n",
    "    \n",
    "    # Initialisiere die Konfusionsmatrix für 20 Cityscapes-Klassen\n",
    "    confusion_matrix = torch.zeros(20, 20, dtype=torch.int64).to(device)\n",
    "    \n",
    "    # Inferenzschleife über das Testset mit Fortschrittsanzeige\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=f\"Evaluating {model_name}\", leave=True):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)  # Ground Truth im Cityscapes-Format (0-19)\n",
    "            \n",
    "            # Modellinferenz: Output hat 124 Kanäle\n",
    "            output = model_loaded.model(images)['out']  # [1, 124, H, W]\n",
    "            predicted_mapillary = output.argmax(1).squeeze(0)  # [H, W]\n",
    "            \n",
    "            # Mappen auf 20 Cityscapes-Klassen\n",
    "            predicted_cityscapes = map_model_output_to_cityscapes(predicted_mapillary)\n",
    "            \n",
    "            # Aktualisiere die Konfusionsmatrix\n",
    "            for cls in range(20):\n",
    "                for cls_pred in range(20):\n",
    "                    confusion_matrix[cls, cls_pred] += torch.sum((labels.squeeze(0) == cls) & (predicted_cityscapes == cls_pred)).item()\n",
    "    \n",
    "    # Berechnung der mIoU und iou pro Klasse\n",
    "    intersection = confusion_matrix.diag().float()\n",
    "    gt_total = confusion_matrix.sum(dim=1).float()\n",
    "    pred_total = confusion_matrix.sum(dim=0).float()\n",
    "    union = gt_total + pred_total - intersection\n",
    "    iou_per_class = intersection / (union + 1e-6)\n",
    "    miou = iou_per_class.mean().item()\n",
    "    \n",
    "    evaluation_results[model_name] = {\n",
    "        \"confusion_matrix\": confusion_matrix.cpu().numpy().tolist(),\n",
    "        \"mIoU\": miou,\n",
    "        \"iou_per_class\": iou_per_class.cpu().numpy().tolist()\n",
    "    }\n",
    "    \n",
    "    print(f\"Ergebnisse für {model_name}: mIoU = {miou:.4f}\")\n",
    "\n",
    "# Speichere die Evaluationsergebnisse als JSON\n",
    "save_path = \"/home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/FINAL_DATEN/evaluation_results_mapillary_on_cityscapes.json\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(evaluation_results, f, indent=4)\n",
    "    \n",
    "print(f\"\\nEvaluationsergebnisse wurden gespeichert in: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
