{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 1: Imports\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 2: Parameterdefinition\n",
    "# Pfad zu deinem Ordner mit Kalibrierungsbildern\n",
    "calibration_data_path = \"Mapillary_Vistas/validation/images\"  # Passe diesen Pfad an\n",
    "\n",
    "# Pfad, wo die vorverarbeiteten Daten dauerhaft gespeichert werden sollen (Cache-Datei)\n",
    "cache_file = \"Kalibr_Cache/cache_file.h5\"  # Passe diesen Pfad an\n",
    "\n",
    "# Zielgröße für die Bilder: (Channels, Height, Width)\n",
    "target_shape = (3, 520, 520)\n",
    "\n",
    "# Maximale Anzahl an Bildern, die verarbeitet werden sollen\n",
    "max_samples = 600\n",
    "\n",
    "# Anzahl der Bilder pro Batch (zur Reduzierung des RAM-Verbrauchs)\n",
    "batch_size = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 3: Funktion zur Vorverarbeitung und Speicherung der Kalibrierungsdaten\n",
    "def process_and_save_calibration_data(calibration_data_path, target_shape, cache_file, max_samples, batch_size):\n",
    "    \"\"\"\n",
    "    Liest bis zu max_samples Bilder aus dem Ordner calibration_data_path, verarbeitet diese in Batches,\n",
    "    und speichert sie in einem HDF5-File cache_file.\n",
    "    \n",
    "    :param calibration_data_path: Ordnerpfad mit den Kalibrierungsbildern.\n",
    "    :param target_shape: Zielgröße als (Channels, Height, Width), z. B. (3, 520, 520).\n",
    "    :param cache_file: Pfad zur HDF5-Datei, in der die vorverarbeiteten Bilder dauerhaft gespeichert werden.\n",
    "    :param max_samples: Maximale Anzahl an Bildern, die verarbeitet werden sollen.\n",
    "    :param batch_size: Anzahl der Bilder, die pro Batch verarbeitet werden.\n",
    "    \"\"\"\n",
    "    # Alle Bildpfade im Ordner sammeln\n",
    "    all_images = [os.path.join(calibration_data_path, f)\n",
    "                  for f in os.listdir(calibration_data_path)\n",
    "                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    # Falls max_samples gesetzt ist, wähle zufällig bis zu max_samples Bilder aus\n",
    "    if max_samples is not None:\n",
    "        all_images = random.sample(all_images, min(len(all_images), max_samples))\n",
    "    total_images = len(all_images)\n",
    "    \n",
    "    print(f\"Verarbeite {total_images} Bilder in Batches à {batch_size} und speichere in '{cache_file}'...\")\n",
    "    \n",
    "    # Erstelle das HDF5-File mit einem Dataset für alle Bilder:\n",
    "    with h5py.File(cache_file, 'w') as hf:\n",
    "        # Erstelle ein Dataset mit der Form (total_images, Channels, Height, Width)\n",
    "        dset = hf.create_dataset(\"calibration_images\", shape=(total_images,) + target_shape, dtype=np.float32)\n",
    "        \n",
    "        idx = 0\n",
    "        # Verwende tqdm, um die Verarbeitung der Batches anzuzeigen\n",
    "        for i in tqdm(range(0, total_images, batch_size), desc=\"Verarbeite Batches\"):\n",
    "            batch_paths = all_images[i:i+batch_size]\n",
    "            batch_data = []\n",
    "            for img_path in batch_paths:\n",
    "                image = cv2.imread(img_path)\n",
    "                if image is None:\n",
    "                    continue\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                # Zielgröße: target_shape ist (C, H, W) – also Resize auf (target_shape[2], target_shape[1])\n",
    "                image = cv2.resize(image, (target_shape[2], target_shape[1]))\n",
    "                image = image.astype(np.float32) / 255.0\n",
    "                # Transponiere das Bild in die Form (C, H, W)\n",
    "                image = np.transpose(image, (2, 0, 1))\n",
    "                batch_data.append(image)\n",
    "            if batch_data:\n",
    "                batch_data = np.stack(batch_data, axis=0)\n",
    "                dset[idx: idx + batch_data.shape[0]] = batch_data\n",
    "                idx += batch_data.shape[0]\n",
    "    print(f\"Kalibrierungsdaten für {total_images} Bilder wurden in '{cache_file}' gespeichert.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verarbeite 600 Bilder in Batches à 50 und speichere in 'Kalibr_Cache/cache_file.h5'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verarbeite Batches: 100%|██████████| 12/12 [00:48<00:00,  4.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalibrierungsdaten für 600 Bilder wurden in 'Kalibr_Cache/cache_file.h5' gespeichert.\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 4: Ausführung der Funktion\n",
    "# Starte den Vorverarbeitungsprozess:\n",
    "process_and_save_calibration_data(\n",
    "    calibration_data_path=calibration_data_path,\n",
    "    target_shape=target_shape,\n",
    "    cache_file=cache_file,\n",
    "    max_samples=max_samples,\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
