{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jan/anaconda3/envs/studi/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2025-03-21 15:35:24.423218: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-21 15:35:25.436242: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import ray.cloudpickle as pickle\n",
    "from Helper.ml_models import *  # Enthält z. B. TrainedModel und K_Fold_Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data leaks found.\n",
      "Cityscapes Test-Dataset: 695 Samples gefunden.\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = \"/home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation\"\n",
    "\n",
    "# Checkpoints und Ausgabeordner\n",
    "CHECKPOINT_DIR = os.path.join(BASE_PATH, \"FINAL_DATEN/hyper_city\")\n",
    "CONF_MATRIX_DIR = os.path.join(BASE_PATH, \"FINAL_DATEN/confusion_matrices_city\")\n",
    "os.makedirs(CONF_MATRIX_DIR, exist_ok=True)\n",
    "\n",
    "# Cityscapes: 20 Klassen\n",
    "NUM_CLASSES = 20\n",
    "\n",
    "\n",
    "k_fold_dataset = K_Fold_Dataset(\n",
    "    image_dir='CityscapesDaten/images',\n",
    "    annotation_dir='CityscapesDaten/semantic',\n",
    "    k_fold_csv_dir='Daten/CityscapesDaten',\n",
    "    leave_out_fold=0\n",
    ")\n",
    "k_fold_dataset.check_for_data_leaks()\n",
    "print(f\"Cityscapes Test-Dataset: {len(k_fold_dataset.test_dataset)} Samples gefunden.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpointed_model_city(model_name, checkpoint_path, num_classes):\n",
    "    \"\"\"\n",
    "    Lädt ein Cityscapes-Modell aus dem Checkpoint.\n",
    "    Nutzt die Klasse TrainedModel aus Helper.ml_models.\n",
    "    \"\"\"\n",
    "    model = TrainedModel(\n",
    "        model_name=model_name,\n",
    "        width=2048,      # Passen Sie ggf. die Eingabegröße an\n",
    "        height=1024,     # Passen Sie ggf. die Eingabegröße an\n",
    "        weights_name='',\n",
    "        skip_local_load=True,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    with open(checkpoint_path, \"rb\") as fp:\n",
    "        checkpoint_data = pickle.load(fp)\n",
    "    model.model.load_state_dict(checkpoint_data[\"model_state\"], strict=True)\n",
    "    if \"optimizer_state\" in checkpoint_data:\n",
    "        model.optimizer.load_state_dict(checkpoint_data[\"optimizer_state\"])\n",
    "    model.model.eval()\n",
    "    return model\n",
    "\n",
    "def compute_confusion_matrix(predicted, ground_truth, num_classes):\n",
    "    \"\"\"\n",
    "    Berechnet die Confusion Matrix für ein einzelnes Bild.\n",
    "    \"\"\"\n",
    "    mask = (ground_truth >= 0) & (ground_truth < num_classes)\n",
    "    label = num_classes * ground_truth[mask] + predicted[mask]\n",
    "    count = torch.bincount(label, minlength=num_classes**2)\n",
    "    confusion_matrix = count.reshape(num_classes, num_classes)\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 checkpoint(s) in /home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/FINAL_DATEN/hyper_city\n",
      "\n",
      "Processing model: fcn_resnet101\n",
      "Using checkpoint: /home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/FINAL_DATEN/hyper_city/fcn_resnet101_best_checkpoint.pkl\n",
      "Using CUDA GPU\n",
      "Model loaded: fcn_resnet101 | Device: cuda \n",
      "Skipping local .pth load logic (likely using external Ray checkpoint).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating fcn_resnet101: 100%|██████████| 695/695 [01:12<00:00,  9.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for fcn_resnet101 saved to: /home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/FINAL_DATEN/confusion_matrices_city/fcn_resnet101_confusion_matrix.pt\n",
      "\n",
      "Processing model: deeplabv3_mobilenet_v3_large\n",
      "Using checkpoint: /home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/FINAL_DATEN/hyper_city/deeplabv3_mobilenet_v3_large_best_checkpoint.pkl\n",
      "Using CUDA GPU\n",
      "Model loaded: deeplabv3_mobilenet_v3_large | Device: cuda \n",
      "Skipping local .pth load logic (likely using external Ray checkpoint).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating deeplabv3_mobilenet_v3_large: 100%|██████████| 695/695 [00:51<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for deeplabv3_mobilenet_v3_large saved to: /home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/FINAL_DATEN/confusion_matrices_city/deeplabv3_mobilenet_v3_large_confusion_matrix.pt\n",
      "\n",
      "Processing model: fcn_resnet50\n",
      "Using checkpoint: /home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/FINAL_DATEN/hyper_city/fcn_resnet50_best_checkpoint.pkl\n",
      "Using CUDA GPU\n",
      "Model loaded: fcn_resnet50 | Device: cuda \n",
      "Skipping local .pth load logic (likely using external Ray checkpoint).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating fcn_resnet50: 100%|██████████| 695/695 [00:58<00:00, 11.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for fcn_resnet50 saved to: /home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/FINAL_DATEN/confusion_matrices_city/fcn_resnet50_confusion_matrix.pt\n",
      "\n",
      "Processing model: lraspp_mobilenet_v3_large\n",
      "Using checkpoint: /home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/FINAL_DATEN/hyper_city/lraspp_mobilenet_v3_large_best_checkpoint.pkl\n",
      "Using CUDA GPU\n",
      "Model loaded: lraspp_mobilenet_v3_large | Device: cuda \n",
      "Skipping local .pth load logic (likely using external Ray checkpoint).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating lraspp_mobilenet_v3_large: 100%|██████████| 695/695 [00:50<00:00, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for lraspp_mobilenet_v3_large saved to: /home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/FINAL_DATEN/confusion_matrices_city/lraspp_mobilenet_v3_large_confusion_matrix.pt\n",
      "\n",
      "Processing model: deeplabv3_resnet101\n",
      "Using checkpoint: /home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/FINAL_DATEN/hyper_city/deeplabv3_resnet101_best_checkpoint.pkl\n",
      "Using CUDA GPU\n",
      "Model loaded: deeplabv3_resnet101 | Device: cuda \n",
      "Skipping local .pth load logic (likely using external Ray checkpoint).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating deeplabv3_resnet101: 100%|██████████| 695/695 [01:07<00:00, 10.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for deeplabv3_resnet101 saved to: /home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/FINAL_DATEN/confusion_matrices_city/deeplabv3_resnet101_confusion_matrix.pt\n",
      "\n",
      "Processing model: deeplabv3_resnet50\n",
      "Using checkpoint: /home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/FINAL_DATEN/hyper_city/deeplabv3_resnet50_best_checkpoint.pkl\n",
      "Using CUDA GPU\n",
      "Model loaded: deeplabv3_resnet50 | Device: cuda \n",
      "Skipping local .pth load logic (likely using external Ray checkpoint).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating deeplabv3_resnet50: 100%|██████████| 695/695 [01:01<00:00, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for deeplabv3_resnet50 saved to: /home/jan/studienarbeit/Studienarbeit-CODE_Semantische_Segmentation/FINAL_DATEN/confusion_matrices_city/deeplabv3_resnet50_confusion_matrix.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Liste aller Checkpoint-Dateien (.pkl) im CHECKPOINT_DIR\n",
    "checkpoint_files = glob.glob(os.path.join(CHECKPOINT_DIR, \"*.pkl\"))\n",
    "print(f\"Found {len(checkpoint_files)} checkpoint(s) in {CHECKPOINT_DIR}\")\n",
    "\n",
    "for checkpoint_path in checkpoint_files:\n",
    "    # Extrahiere den Modellnamen aus dem Dateinamen, z.B.:\n",
    "    # \"deeplabv3_mobilenet_v3_large_best_checkpoint.pkl\" -> \"deeplabv3_mobilenet_v3_large\"\n",
    "    base_name = os.path.basename(checkpoint_path)\n",
    "    model_name = base_name.split(\"_best_checkpoint.pkl\")[0]\n",
    "    print(f\"\\nProcessing model: {model_name}\")\n",
    "    print(f\"Using checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    try:\n",
    "        model_loaded = load_checkpointed_model_city(model_name, checkpoint_path, NUM_CLASSES)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Could not load model {model_name}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Initialisiere eine leere Confusion Matrix\n",
    "    confusion_matrix_total = torch.zeros((NUM_CLASSES, NUM_CLASSES), dtype=torch.int64)\n",
    "    \n",
    "    # Evaluierung über den Test-Datensatz\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(len(k_fold_dataset.test_dataset)), desc=f\"Evaluating {model_name}\"):\n",
    "            image, annotation = k_fold_dataset.test_dataset[i]\n",
    "            # Führe Inferenz durch – hier wird angenommen, dass model_loaded.inference(image) den Logits-Tensor liefert\n",
    "            output = model_loaded.inference(image)\n",
    "            predicted = output.argmax(1).squeeze(0)\n",
    "            \n",
    "            cm = compute_confusion_matrix(predicted.cpu(), annotation.cpu(), NUM_CLASSES)\n",
    "            confusion_matrix_total += cm\n",
    "    \n",
    "    # Speichere die resultierende Confusion Matrix\n",
    "    save_path = os.path.join(CONF_MATRIX_DIR, f\"{model_name}_confusion_matrix.pt\")\n",
    "    torch.save(confusion_matrix_total, save_path)\n",
    "    print(f\"Confusion Matrix for {model_name} saved to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
